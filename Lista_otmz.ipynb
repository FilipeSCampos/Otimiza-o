{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhpsVkwNMwhjjdQ3/VxCN4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgwpXLrkfFbQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lista 1"
      ],
      "metadata": {
        "id": "0V48_PrOfH0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5-jBxHcpfGl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo em estimar o vetor de parâmetros beta é encontrar os coeficientes que melhor descrevem a relação entre as variáveis independentes (idade, gênero, número de dependentes, fumante/não-fumante) e a variável dependente (despesas médicas). Esses coeficientes minimizam a diferença entre os valores observados e os valores preditos pelo modelo, geralmente utilizando o critério de mínimos quadrados."
      ],
      "metadata": {
        "id": "IWksAVByfVwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "url = \"https://raw.githubusercontent.com/Cayan-Portela/ceub/main/dados/insurance_teste.csv\"\n",
        "data = pd.read_csv(url, sep=';')\n",
        "\n",
        "\n",
        "# Substituir vírgulas por pontos e converter colunas 'bmi' e 'charges' para float\n",
        "data['bmi'] = data['bmi'].str.replace(',', '.').astype(float)\n",
        "data['charges'] = data['charges'].str.replace(',', '.').astype(float)\n",
        "\n",
        "# Pré-processamento\n",
        "data['sex'] = data['sex'].map({'male': 0, 'female': 1})\n",
        "data['smoker'] = data['smoker'].map({'yes': 1, 'no': 0})\n",
        "data = pd.get_dummies(data, columns=['region'], drop_first=True)\n",
        "\n",
        "# Definir variáveis independentes e dependentes\n",
        "X = data[['age', 'sex', 'children', 'smoker']].values\n",
        "Y = data['charges'].values\n",
        "\n",
        "# Converter Y para array NumPy e garantir que seja uma coluna\n",
        "Y = Y.reshape(-1, 1)\n",
        "\n",
        "# Escalonamento das variáveis\n",
        "mean_X = np.mean(X, axis=0)\n",
        "std_X = np.std(X, axis=0)\n",
        "X_scaled = (X - mean_X) / std_X\n",
        "\n",
        "# Adicionar o intercepto\n",
        "X_scaled = np.c_[np.ones(X_scaled.shape[0]), X_scaled]\n",
        "\n",
        "# Funções auxiliares para operações matriciais\n",
        "def matrix_multiply(A, B):\n",
        "    return np.dot(A, B)\n",
        "\n",
        "def transpose(A):\n",
        "    return np.transpose(A)\n",
        "\n",
        "def inverse(A):\n",
        "    return np.linalg.inv(A)\n",
        "\n",
        "# Solução analítica\n",
        "XT = transpose(X_scaled)\n",
        "XTX = matrix_multiply(XT, X_scaled)\n",
        "XTX_inv = inverse(XTX)\n",
        "XTY = matrix_multiply(XT, Y)\n",
        "\n",
        "beta_hat = matrix_multiply(XTX_inv, XTY)\n",
        "\n",
        "print(\"Vetor de parâmetros estimado (beta_hat):\", beta_hat.ravel())\n",
        "\n",
        "# Decomposição QR\n",
        "def gram_schmidt(A):\n",
        "    (num_rows, num_cols) = A.shape\n",
        "    Q = np.zeros((num_rows, num_cols))\n",
        "    R = np.zeros((num_cols, num_cols))\n",
        "\n",
        "    for j in range(num_cols):\n",
        "        v = A[:, j]\n",
        "        for i in range(j):\n",
        "            q = Q[:, i]\n",
        "            R[i, j] = q.dot(v)\n",
        "            v = v - R[i, j] * q\n",
        "        R[j, j] = np.linalg.norm(v)\n",
        "        Q[:, j] = v / R[j, j]\n",
        "\n",
        "    return Q, R\n",
        "\n",
        "Q, R = gram_schmidt(X_scaled)\n",
        "QTY = matrix_multiply(transpose(Q), Y)\n",
        "beta_hat_qr = matrix_multiply(inverse(R), QTY)\n",
        "\n",
        "print(\"Vetor de parâmetros estimado via QR (beta_hat_qr):\", beta_hat_qr.ravel())\n",
        "\n",
        "# Função de custo (Erro Quadrático Médio)\n",
        "def compute_cost(X, Y, beta):\n",
        "    m = len(Y)\n",
        "    J = np.sum((matrix_multiply(X, beta) - Y) ** 2) / (2 * m)\n",
        "    return J\n",
        "\n",
        "# Gradiente descendente\n",
        "def gradient_descent(X, Y, beta, learning_rate, num_iterations):\n",
        "    m = len(Y)\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        gradient = matrix_multiply(transpose(X), (matrix_multiply(X, beta) - Y)) / m\n",
        "        beta = beta - learning_rate * gradient\n",
        "\n",
        "        # Verificação de overflow\n",
        "        if np.any(np.isnan(beta)) or np.any(np.isinf(beta)):\n",
        "            print(\"Warning: overflow detected. Stopping gradient descent.\")\n",
        "            break\n",
        "\n",
        "        cost_history.append(compute_cost(X, Y, beta))\n",
        "\n",
        "    return beta, cost_history\n",
        "\n",
        "# Inicialização dos parâmetros\n",
        "beta = np.zeros((X_scaled.shape[1], 1))\n",
        "learning_rate = 0.01  # Ajustar a taxa de aprendizado\n",
        "num_iterations = 1000\n",
        "\n",
        "# Execução do gradiente descendente\n",
        "beta_hat_gd, cost_history = gradient_descent(X_scaled, Y, beta, learning_rate, num_iterations)\n",
        "\n",
        "print(\"Vetor de parâmetros estimado via Gradiente Descendente (beta_hat_gd):\", beta_hat_gd.ravel())\n",
        "\n",
        "# Função de predição\n",
        "def predict(X, beta):\n",
        "    return matrix_multiply(X, beta)\n",
        "\n",
        "# Predições\n",
        "Y_pred_analytical = predict(X_scaled, beta_hat)\n",
        "Y_pred_qr = predict(X_scaled, beta_hat_qr)\n",
        "Y_pred_gd = predict(X_scaled, beta_hat_gd)\n",
        "\n",
        "# Função de cálculo do MSE\n",
        "def mean_squared_error(Y_true, Y_pred):\n",
        "    return np.sum((Y_true - Y_pred) ** 2) / len(Y_true)\n",
        "\n",
        "# Cálculo do MSE\n",
        "mse_analytical = mean_squared_error(Y, Y_pred_analytical)\n",
        "mse_qr = mean_squared_error(Y, Y_pred_qr)\n",
        "mse_gd = mean_squared_error(Y, Y_pred_gd)\n",
        "\n",
        "print(\"MSE - Solução Analítica:\", mse_analytical)\n",
        "print(\"MSE - Decomposição QR:\", mse_qr)\n",
        "print(\"MSE - Gradiente Descendente:\", mse_gd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh8N-LpPjGks",
        "outputId": "dd4baaed-cabf-473c-e1ae-12645f2e43a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor de parâmetros estimado (beta_hat): [13943.61574115  3844.25775649  -268.15636338   357.33165539\n",
            "  9777.44641836]\n",
            "Vetor de parâmetros estimado via QR (beta_hat_qr): [13943.61574115  3844.25775649  -268.15636338   357.33165539\n",
            "  9777.44641836]\n",
            "Vetor de parâmetros estimado via Gradiente Descendente (beta_hat_gd): [13943.01377787  3844.15476092  -268.48257983   357.26909347\n",
            "  9776.91431131]\n",
            "MSE - Solução Analítica: 47740252.73553374\n",
            "MSE - Decomposição QR: 47740252.73553373\n",
            "MSE - Gradiente Descendente: 47740253.474948265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questao 2\n"
      ],
      "metadata": {
        "id": "meyqRHitkrTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Objetivo da Modelagem de Regressão Logística\n",
        "O objetivo da modelagem de regressão logística é prever a probabilidade de um evento ocorrer, com base em variáveis independentes. No caso deste conjunto de dados, o objetivo provavelmente é prever se um cliente irá adquirir um produto (por exemplo, um cartão de crédito) ou não, com base em variáveis como gênero, idade, histórico de crédito etc."
      ],
      "metadata": {
        "id": "6t8z0ZV9k0Kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de Perda (Entropia Cruzada Negativa) para Regressão Logística:\n",
        "\n",
        "\\[ \\text{Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)] ]\\\n",
        "\n",
        "### Derivação da Função de Perda:\n",
        "\n",
        "Para encontrar os parâmetros \\( \\beta \\) que maximizam a função de perda, precisamos calcular a derivada da função de perda em relação a cada parâmetro \\( \\beta_j \\). A derivada da função de perda em relação a \\( \\beta_j \\) é dada por:\n",
        "\n",
        "\\[ \\frac{\\partial \\text{Loss}}{\\partial \\beta_j} = -\\frac{1}{n} \\sum_{i=1}^{n} (y_i - p_i) x_{ij} \\]\n",
        "\n",
        "onde:\n",
        "- \\( n \\) é o número de observações\n",
        "- \\( y_i \\) é a variável de resposta (0 ou 1)\n",
        "- \\( p_i \\) é a probabilidade estimada da classe positiva\n",
        "- \\( x_{ij} \\) é o valor da variável independente \\( j \\) para a observação \\( i \\)\n",
        "\n",
        "Essa derivação é usada nas atualizações dos parâmetros no método de Newton-Raphson e no gradiente descendente para encontrar os parâmetros ótimos do modelo de regressão logística.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M3r0WTPDk2WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "url = 'https://raw.githubusercontent.com/Cayan-Portela/ceub/main/dados/bank_customer_treino.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Pré-processamento\n",
        "# Codificar variáveis categóricas (gender, country)\n",
        "data = pd.get_dummies(data, columns=['gender', 'country'], drop_first=True)\n",
        "\n",
        "# Dividir os dados em variáveis independentes (X) e variável dependente (y)\n",
        "X = data[['credit_score', 'age', 'credit_card']].values\n",
        "y = data['churn'].values\n"
      ],
      "metadata": {
        "id": "LSWPgQzSlXad"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Adicionar o intercepto aos dados\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "# Função logística\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Método de Newton-Raphson\n",
        "def newton_raphson(X, y, max_iter=1000, tol=1e-6):\n",
        "    beta = np.zeros(X.shape[1])\n",
        "    m = len(y)\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        # Calcular as probabilidades previstas\n",
        "        pi = sigmoid(np.dot(X, beta))\n",
        "\n",
        "        # Calcular a matriz diagonal W\n",
        "        W = np.diag(pi * (1 - pi))\n",
        "\n",
        "        # Calcular o vetor de erros\n",
        "        error = np.dot(X.T, (y - pi))\n",
        "\n",
        "        # Calcular a matriz Hessian\n",
        "        hessian = np.dot(X.T, np.dot(W, X))\n",
        "\n",
        "        # Atualizar os parâmetros beta\n",
        "        beta_old = beta\n",
        "        beta = beta + np.dot(np.linalg.inv(hessian), error)\n",
        "\n",
        "        # Critério de parada\n",
        "        if np.linalg.norm(beta - beta_old) < tol:\n",
        "            break\n",
        "\n",
        "    return beta\n",
        "\n",
        "# Estimar os parâmetros beta usando o método de Newton-Raphson\n",
        "beta_newton_raphson = newton_raphson(X, y)\n",
        "print(\"Vetor de parâmetros estimado (Newton-Raphson):\", beta_newton_raphson)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAQm96_pmC7l",
        "outputId": "920e25a7-740d-4963-b56c-dc8efdea713d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor de parâmetros estimado (Newton-Raphson): [-3.51023852e+00 -6.34010669e-04  6.38419769e-02 -5.35868008e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradiente Descendente\n",
        "def gradient_descent(X, y, learning_rate=0.001, max_iter=1000, tol=1e-6):\n",
        "    beta = np.zeros(X.shape[1])\n",
        "    m = len(y)\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        # Calcular as probabilidades previstas\n",
        "        pi = sigmoid(np.dot(X, beta))\n",
        "\n",
        "        # Calcular o gradiente da função de perda\n",
        "        gradient = np.dot(X.T, (y - pi))\n",
        "\n",
        "        # Atualizar os parâmetros beta\n",
        "        beta_old = beta\n",
        "        beta = beta + learning_rate * gradient\n",
        "\n",
        "        # Critério de parada\n",
        "        if np.linalg.norm(beta - beta_old) < tol:\n",
        "            break\n",
        "\n",
        "    return beta\n",
        "\n",
        "# Estimar os parâmetros beta usando o gradiente descendente\n",
        "beta_gradient_descent = gradient_descent(X, y)\n",
        "print(\"Vetor de parâmetros estimado (Gradiente Descendente):\", beta_gradient_descent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiXMuSROmPnr",
        "outputId": "3461d1ed-e1e1-43bf-b7f5-c4da8f02f088"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-49e55c2a0d2d>:8: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor de parâmetros estimado (Gradiente Descendente): [-1.68831613e+00 -2.31171506e+03  6.60992852e+03 -1.52108943e+01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Criar o modelo de regressão logística\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Treinar o modelo\n",
        "log_reg.fit(X, y)\n",
        "\n",
        "# Obter os coeficientes (betas)\n",
        "beta_sklearn = np.concatenate((log_reg.intercept_, log_reg.coef_[0]))\n",
        "\n",
        "print(\"Vetor de parâmetros estimado (Scikit-learn):\", beta_sklearn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S2MzLDRnQfU",
        "outputId": "273f0a14-101e-4405-fbdb-4e49b6200a34"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor de parâmetros estimado (Scikit-learn): [-1.73006874e+00 -1.72144868e+00 -6.99082742e-04  6.35218949e-02\n",
            " -5.66306945e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Newton Raphson para raiz de funcao\n"
      ],
      "metadata": {
        "id": "JY0zasUBoHYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_raphson_sqrt(n, precision=1e-10):\n",
        "    # Função cuja raiz queremos encontrar: f(x) = x^2 - n\n",
        "    def f(x):\n",
        "        return x**2 - n\n",
        "\n",
        "    # Derivada da função f(x): f'(x) = 2x\n",
        "    def f_prime(x):\n",
        "        return 2 * x\n",
        "\n",
        "    # Estimativa inicial\n",
        "    x = n / 2\n",
        "\n",
        "    # Iterar até atingir a precisão desejada\n",
        "    while True:\n",
        "        # Atualizar a estimativa da raiz usando o método de Newton-Raphson\n",
        "        x_next = x - f(x) / f_prime(x)\n",
        "\n",
        "        # Verificar a condição de parada\n",
        "        if abs(x_next - x) < precision:\n",
        "            break\n",
        "\n",
        "        # Atualizar a estimativa atual da raiz\n",
        "        x = x_next\n",
        "\n",
        "    return x\n",
        "\n",
        "# Encontrar a raiz quadrada de 10 com precisão de 10 casas decimais\n",
        "sqrt_10 = newton_raphson_sqrt(10)\n",
        "print(\"Raiz quadrada de 10:\", sqrt_10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZW2h5nunZRJ",
        "outputId": "bcae869e-1afd-4fd9-8489-27b241de4e0c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raiz quadrada de 10: 3.1622776601683795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Achar raiz de funcao"
      ],
      "metadata": {
        "id": "rAe05dXTolTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_raphson(f, f_prime, x0, tol=1e-10, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Função para encontrar a raiz de uma equação usando o método de Newton-Raphson.\n",
        "\n",
        "    Args:\n",
        "    - f: Função cuja raiz queremos encontrar.\n",
        "    - f_prime: Derivada da função f.\n",
        "    - x0: Estimativa inicial.\n",
        "    - tol: Tolerância (critério de parada).\n",
        "    - max_iter: Número máximo de iterações permitidas.\n",
        "\n",
        "    Returns:\n",
        "    - Aproximação da raiz da função.\n",
        "    \"\"\"\n",
        "    x = x0\n",
        "    iter_count = 0\n",
        "\n",
        "    while True:\n",
        "        x_next = x - f(x) / f_prime(x)\n",
        "        iter_count += 1\n",
        "\n",
        "        if abs(x_next - x) < tol or iter_count >= max_iter:\n",
        "            break\n",
        "\n",
        "        x = x_next\n",
        "\n",
        "    return x\n",
        "\n",
        "# Definir a função e sua derivada\n",
        "def f(x):\n",
        "    return x**4 - 2*x**3 - 2\n",
        "\n",
        "def f_prime(x):\n",
        "    return 4*x**3 - 6*x**2\n",
        "\n",
        "# Estimativa inicial dentro do intervalo [1, 2]\n",
        "x0 = 1.501\n",
        "\n",
        "# Encontrar a raiz usando o método de Newton-Raphson\n",
        "root = newton_raphson(f, f_prime, x0)\n",
        "\n",
        "print(\"Raiz encontrada:\", root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JUiu8WwoWzA",
        "outputId": "77ba9814-00ed-4a5e-a9ed-e5bb17b5721c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raiz encontrada: 2.1903279467148673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_raphson_steps(f, f_prime, x0, num_steps):\n",
        "    \"\"\"\n",
        "    Função para calcular os primeiros passos do algoritmo de Newton-Raphson.\n",
        "\n",
        "    Args:\n",
        "    - f: Função cuja raiz queremos encontrar.\n",
        "    - f_prime: Derivada da função f.\n",
        "    - x0: Estimativa inicial.\n",
        "    - num_steps: Número de passos a serem calculados.\n",
        "\n",
        "    Returns:\n",
        "    - Lista contendo os valores de x em cada passo.\n",
        "    \"\"\"\n",
        "    x_values = [x0]\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        x_next = x_values[-1] - f(x_values[-1]) / f_prime(x_values[-1])\n",
        "        x_values.append(x_next)\n",
        "\n",
        "    return x_values\n",
        "\n",
        "# Definir a função e sua derivada\n",
        "def f(x):\n",
        "    return 3 * x**(1/3)\n",
        "\n",
        "def f_prime(x):\n",
        "    return 1 / (x**(2/3))\n",
        "\n",
        "# Estimativa inicial\n",
        "x0 = 0.1\n",
        "\n",
        "# Número de passos\n",
        "num_steps = 10\n",
        "\n",
        "# Calcular os 10 primeiros passos do algoritmo de Newton-Raphson\n",
        "steps = newton_raphson_steps(f, f_prime, x0, num_steps)\n",
        "\n",
        "# Imprimir os resultados\n",
        "for i, x in enumerate(steps):\n",
        "    print(f\"Passo {i}: x = {x:.10f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMO476lNpD_K",
        "outputId": "f541b968-a8c5-43f7-8714-21b71fc0d684"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passo 0: x = 0.1000000000\n",
            "Passo 1: x = -0.2000000000\n",
            "Passo 2: x = 0.4000000000-0.0000000000j\n",
            "Passo 3: x = -0.8000000000+0.0000000000j\n",
            "Passo 4: x = 1.6000000000-0.0000000000j\n",
            "Passo 5: x = -3.2000000000+0.0000000000j\n",
            "Passo 6: x = 6.4000000000-0.0000000000j\n",
            "Passo 7: x = -12.8000000000+0.0000000000j\n",
            "Passo 8: x = 25.6000000000-0.0000000000j\n",
            "Passo 9: x = -51.2000000000+0.0000000000j\n",
            "Passo 10: x = 102.4000000000-0.0000000000j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_raphson(f, f_prime, x0, tol=1e-10, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Função para encontrar a raiz de uma equação usando o método de Newton-Raphson.\n",
        "\n",
        "    Args:\n",
        "    - f: Função cuja raiz queremos encontrar.\n",
        "    - f_prime: Derivada da função f.\n",
        "    - x0: Estimativa inicial.\n",
        "    - tol: Tolerância (critério de parada).\n",
        "    - max_iter: Número máximo de iterações permitidas.\n",
        "\n",
        "    Returns:\n",
        "    - Aproximação da raiz da função.\n",
        "    \"\"\"\n",
        "    x = x0\n",
        "    iter_count = 0\n",
        "\n",
        "    while True:\n",
        "        x_next = x - f(x) / f_prime(x)\n",
        "        iter_count += 1\n",
        "\n",
        "        if abs(x_next - x) < tol or iter_count >= max_iter:\n",
        "            break\n",
        "\n",
        "        x = x_next\n",
        "\n",
        "    return x\n",
        "\n",
        "# Definir a função e sua derivada\n",
        "def f(x):\n",
        "    return x**4 - 5*x**3 + 9*x + 3\n",
        "\n",
        "def f_prime(x):\n",
        "    return 4*x**3 - 15*x**2 + 9\n",
        "\n",
        "# Estimativa inicial dentro do intervalo [4, 6]\n",
        "x0 = 5\n",
        "# Encontrar a raiz usando o método de Newton-Raphson\n",
        "root = newton_raphson(f, f_prime, x0)\n",
        "\n",
        "print(\"Raiz encontrada:\", root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXMQ2bAmpa-z",
        "outputId": "7cb62543-c729-4024-e162-684e58c87105"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raiz encontrada: 4.528917957294362\n"
          ]
        }
      ]
    }
  ]
}